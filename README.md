# Awesome-ICCV2023-Low-Level-Vision
A Collection of Papers and Codes in ICCV2023 related to Low-Level Vision

**[In Construction]** If you find some missing papers or typos, feel free to pull issues or requests.

## Related collections for low-level vision
- [Awesome-ICCV2021-Low-Level-Vision](https://github.com/DarrenPan/Awesome-ICCV2023-Low-Level-Vision/blob/main/ICCV2021-Low-Level-Vision.md)
- [Awesome-CVPR2023/2022-Low-Level-Vision](https://github.com/DarrenPan/Awesome-CVPR2023-Low-Level-Vision)
- [Awesome-NeurIPS2022/2021-Low-Level-Vision](https://github.com/DarrenPan/Awesome-NeurIPS2022-Low-Level-Vision)
- [Awesome-ECCV2022-Low-Level-Vision](https://github.com/DarrenPan/Awesome-ECCV2022-Low-Level-Vision)
- [Awesome-AAAI2022-Low-Level-Vision](https://github.com/DarrenPan/Awesome-AAAI2022-Low-Level-Vision)
- [Awesome-CVPR2021/2020-Low-Level-Vision](https://github.com/Kobaayyy/Awesome-CVPR2021-CVPR2020-Low-Level-Vision)
- [Awesome-ECCV2020-Low-Level-Vision](https://github.com/Kobaayyy/Awesome-ECCV2020-Low-Level-Vision)



## Overview

- [Image Restoration](#image-restoration)
  - [Video Restoration](#video-restoration)

- [Super Resolution](#super-resolution)
  - [Image Super Resolution](#image-super-resolution)
  - [Video Super Resolution](#video-super-resolution)
- [Image Rescaling](#image-rescaling)

- [Denoising](#denoising)
  - [Image Denoising](#image-denoising)

- [Deblurring](#deblurring)
  - [Image Deblurring](#image-deblurring)
  - [Video Deblurring](#video-deblurring)

- [Deraining](#deraining)

- [Dehazing](#dehazing)

- [HDR Imaging / Multi-Exposure Image Fusion](#hdr-imaging--multi-exposure-image-fusion)

- [Frame Interpolation](#frame-interpolation)

- [Image Enhancement](#image-enhancement)
  - [Low-Light Image Enhancement](#low-light-image-enhancement)

- [Image Harmonization](#image-harmonizationcomposition)

- [Image Completion/Inpainting](#image-completioninpainting)

- [Image Matting](#image-matting)

- [Image Compression](#image-compression)

- [Image Quality Assessment](#image-quality-assessment)

- [Style Transfer](#style-transfer)

- [Image Editing](#image-editing)

- [Image Generation/Synthesis/ Image-to-Image Translation](#image-generationsynthesis--image-to-image-translation)
  - [Video Generation](#video-generation)

- [Others](#others)


# Image Restoration

**DiffIR: Efficient Diffusion Model for Image Restoration**
- Paper: https://arxiv.org/abs/2303.09472
- Code: https://github.com/Zj-BinXia/DiffIR

**Under-Display Camera Image Restoration with Scattering Effect**
- Paper: https://arxiv.org/abs/2308.04163
- Code: https://github.com/NamecantbeNULL/SRUDC
- Tags: Under-Display Camera

**Multi-weather Image Restoration via Domain Translation**
- Paper:
- Code: https://github.com/pwp1208/Domain_Translation_Multi-weather_Restoration
- Tags: Multi-weather

**Towards Authentic Face Restoration with Iterative Diffusion Models and Beyond**
- Paper: https://arxiv.org/abs/2307.08996
- Tags: Authentic Face Restoration, Diffusion

**Physics-Driven Turbulence Image Restoration with Stochastic Refinement**
- Paper: https://arxiv.org/abs/2307.10603
- Code: https://github.com/VITA-Group/PiRN
- Tags: Turbulence Image


## Video Restoration

**Fast Full-frame Video Stabilization with Iterative Optimization**
- Paper: https://arxiv.org/abs/2307.12774
- Code: https://github.com/zwyking/Fast-Stab
- Tags: Video Stabilization

**Minimum Latency Deep Online Video Stabilization**
- Paper: https://arxiv.org/abs/2212.02073
- Code: https://github.com/liuzhen03/NNDVS
- Tags: Video Stabilization

<!--
## Image Reconstruction
## Burst Restoration 
-->

[[Back-to-Overview](#overview)]

# Super Resolution
## Image Super Resolution

**On the Effectiveness of Spectral Discriminators for Perceptual Quality Improvement**
- Paper: https://arxiv.org/abs/2307.12027
- Code: https://github.com/Luciennnnnnn/DualFormer

**SRFormer: Permuted Self-Attention for Single Image Super-Resolution**
- Paper: https://arxiv.org/abs/2303.09735 
- Code: https://github.com/HVision-NKU/SRFormer

**Spatially-Adaptive Feature Modulation for Efficient Image Super-Resolution**
- Paper: https://arxiv.org/abs/2302.13800
- Code: https://github.com/sunny2109/SAFMN

**DLGSANet: Lightweight Dynamic Local and Global Self-Attention Network for Image Super-Resolution**
- Paper: https://arxiv.org/abs/2301.02031
- Code: https://github.com/NeonLeexiang/DLGSANet

**Boosting Single Image Super-Resolution via Partial Channel Shifting**
- Paper: 
- Code: https://github.com/OwXiaoM/_PCS

**Dual Aggregation Transformer for Image Super-Resolution**
- Paper: https://arxiv.org/abs/2308.03364
- Code: https://github.com/zhengchen1999/DAT

**Feature Modulation Transformer: Cross-Refinement of Global Representation via High-Frequency Prior for Image Super-Resolution**
- Paper: https://arxiv.org/abs/2308.05022
- Code: https://github.com/AVC2-UESTC/CRAFT-SR

**Spherical Space Feature Decomposition for Guided Depth Map Super-Resolution**
- Paper: https://arxiv.org/abs/2303.08942
- Code: https://github.com/Zhaozixiang1228/GDSR-SSDNet

**Real-CE: A Benchmark for Chinese-English Scene Text Image Super-resolution**
- Paper: https://arxiv.org/abs/2308.03262
- Code: https://github.com/mjq11302010044/Real-CE
- Tag: Text SR

<!--
## Video Super Resolution
-->

## Spatial-Temporal Video Super-Resolution

**MoTIF: Learning Motion Trajectories with Local Implicit Neural Functions for Continuous Space-Time Video Super-Resolution**
- Paper: https://arxiv.org/abs/2307.07988
- Code: https://github.com/sichun233746/MoTIF

[[Back-to-Overview](#overview)]

# Image Rescaling

**Downscaled Representation Matters: Improving Image Rescaling with Collaborative Downscaled Images**
- Paper: https://arxiv.org/abs/2211.10643

[[Back-to-Overview](#overview)]

# Denoising
## Image Denoising

**Random Sub-Samples Generation for Self-Supervised Real Image Denoising**
- Paper: https://arxiv.org/abs/2307.16825
- Code: https://github.com/p1y2z3/SDAP

**Score Priors Guided Deep Variational Inference for Unsupervised Real-World Single Image Denoising**
- Paper: https://arxiv.org/abs/2308.04682

**The Devil is in the Upsampling: Architectural Decisions Made Simpler for Denoising with Deep Image Prior**
- Paper: https://arxiv.org/abs/2304.11409
- Code: https://github.com/YilinLiu97/FasterDIP-devil-in-upsampling

**Lighting Every Darkness in Two Pairs: A Calibration-Free Pipeline for RAW Denoising**
- Paper: https://arxiv.org/abs/2308.03448
- Code: https://github.com/Srameo/LED

**ExposureDiffusion: Learning to Expose for Low-light Image Enhancement**
- Paper: https://arxiv.org/abs/2307.07710
- Code: https://github.com/wyf0912/ExposureDiffusion

**Towards General Low-Light Raw Noise Synthesis and Modeling**
- Paper: https://arxiv.org/abs/2307.16508
- Code: https://github.com/fengzhang427/LRD
- Tags: Noise Modeling

**Hybrid Spectral Denoising Transformer with Guided Attention**
- Paper: https://arxiv.org/abs/2303.09040
- Code: https://github.com/Zeqiang-Lai/HSDT
- Tags: hyperspectral image denoising
 

[[Back-to-Overview](#overview)]

<!--
## Video Denoising


# Deblurring
## Image Deblurring

## Video Deblurring

[[Back-to-Overview](#overview)]
-->

# Deraining

**From Sky to the Ground: A Large-scale Benchmark and Simple Baseline Towards Real Rain Removal**
- Paper:
- Code: https://github.com/yunguo224/LHP-Rain

**Learning Rain Location Prior for Nighttime Deraining**
- Paper:
- Code: https://github.com/zkawfanx/RLP

[[Back-to-Overview](#overview)]

<!--
# Dehazing

[[Back-to-Overview](#overview)]
# Demosaicing
[[Back-to-Overview](#overview)]
# HDR Imaging / Multi-Exposure Image Fusion

[[Back-to-Overview](#overview)]

-->
# Frame Interpolation

**Video Object Segmentation-aware Video Frame Interpolation**
- Paper:
- Code: https://github.com/junsang7777/VOS-VFI

[[Back-to-Overview](#overview)]

# Image Enhancement

**Iterative Prompt Learning for Unsupervised Backlit Image Enhancement**
- Paper: https://arxiv.org/abs/2303.17569
- Code: https://github.com/ZhexinLiang/CLIP-LIT

## Low-Light Image Enhancement

**ExposureDiffusion: Learning to Expose for Low-light Image Enhancement**
- Paper: https://arxiv.org/abs/2307.07710
- Code: https://github.com/wyf0912/ExposureDiffusion
  
**Implicit Neural Representation for Cooperative Low-light Image Enhancement**
- Paper: https://arxiv.org/abs/2303.11722
- Code: https://github.com/Ysz2022/NeRCo

[[Back-to-Overview](#overview)]

# Image Harmonization/Composition

**Deep Image Harmonization with Learnable Augmentation**
- Paper: https://arxiv.org/abs/2308.00376
- Code: https://github.com/bcmi/SycoNet-Adaptive-Image-Harmonization

**Deep Image Harmonization with Globally Guided Feature Transformation and Relation Distillation**
- Paper: https://arxiv.org/abs/2308.00356
- Code: https://github.com/bcmi/Image-Harmonization-Dataset-ccHarmony


**TF-ICON: Diffusion-Based Training-Free Cross-Domain Image Composition**
- Paper: https://arxiv.org/abs/2307.12493
- Code: https://github.com/Shilin-LU/TF-ICON

[[Back-to-Overview](#overview)]


# Image Completion/Inpainting

**Diverse Inpainting and Editing with GAN Inversion**
- Paper: https://arxiv.org/abs/2307.15033

[[Back-to-Overview](#overview)]

<!--
# Image Matting

[[Back-to-Overview](#overview)]
-->

# Image Stitching

**Parallax-Tolerant Unsupervised Deep Image Stitching**
- Paper: https://arxiv.org/abs/2302.08207
- Code: https://github.com/nie-lang/UDIS2

[[Back-to-Overview](#overview)]

<!--
# Image Compression

[[Back-to-Overview](#overview)]
-->


# Image Quality Assessment

**Delegate Transformer for Image Color Aesthetics Assessment**
- Paper:
- Code: https://github.com/woshidandan/Image-Color-Aesthetics-Assessment/tree/main

**Test Time Adaptation for Blind Image Quality Assessment**
- Paper: https://arxiv.org/abs/2307.14735

**Exploring Video Quality Assessment on User Generated Contents from Aesthetic and Technical Perspectives**
- Paper https://arxiv.org/abs/2211.04894
- Code: https://github.com/VQAssessment/DOVER

[[Back-to-Overview](#overview)]

# Style Transfer

**AesPA-Net: Aesthetic Pattern-Aware Style Transfer Networks**
- Paper: https://arxiv.org/abs/2307.09724
- Code: https://github.com/Kibeom-Hong/AesPA-Net

**Two Birds, One Stone: A Unified Framework for Joint Learning of Image and Video Style Transfers**
- Paper:
- Code: https://github.com/NevSNev/UniST

**All-to-key Attention for Arbitrary Style Transfer**
- Paper:
- Code: https://github.com/LearningHx/StyA2K

[[Back-to-Overview](#overview)]

# Image Editing

**Adaptive Nonlinear Latent Transformation for Conditional Face Editing**
- Paper: https://arxiv.org/abs/2307.07790
- Code: https://github.com/Hzzone/AdaTrans

**Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing**
- Paper: https://arxiv.org/abs/2304.02051
- Code: https://github.com/aimagelab/multimodal-garment-designer 

**MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing**
- Paper: https://arxiv.org/abs/2304.08465
- Code: https://github.com/TencentARC/MasaCtrl

**Not All Steps are Created Equal: Selective Diffusion Distillation for Image Manipulation**
- Paper: https://arxiv.org/abs/2307.08448
- Code: https://github.com/AndysonYs/Selective-Diffusion-Distillation

**HairCLIPv2: Unifying Hair Editing via Proxy Feature Blending**
- Paper: 
- Code: https://github.com/wty-ustc/HairCLIPv2

**StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces**
- Paper: https://arxiv.org/abs/2303.06146
- Code: https://github.com/williamyang1991/StyleGANEX

**Diverse Inpainting and Editing with GAN Inversion**
- Paper: https://arxiv.org/abs/2307.15033

[[Back-to-Overview](#overview)]

# Image Generation/Synthesis / Image-to-Image Translation
## Text-to-Image / Text Guided / Multi-Modal

**MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models**
- Paper: https://arxiv.org/abs/2303.13126
- Code: https://github.com/MagicFusion/MagicFusion.github.io

**ELITE: Encoding Visual Concepts into Textual Embeddings for Customized Text-to-Image Generation**
- Paper: https://arxiv.org/abs/2302.13848
- Code: https://github.com/csyxwei/ELITE

**Better Aligning Text-to-Image Models with Human Preference**
- Paper: https://arxiv.org/abs/2303.14420
- Code: https://github.com/tgxs002/align_sd

**Unleashing Text-to-Image Diffusion Models for Visual Perception**
- Paper: https://arxiv.org/abs/2303.02153
- Code: https://github.com/wl-zhao/VPD

**Unsupervised Compositional Concepts Discovery with Text-to-Image Generative Models**
- Paper: https://arxiv.org/abs/2306.05357
- Code: https://github.com/nanlliu/Unsupervised-Compositional-Concepts-Discovery

**BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion**
- Paper: https://arxiv.org/abs/2307.10816
- Code: https://github.com/Sierkinhane/BoxDiff

**Ablating Concepts in Text-to-Image Diffusion Models**
- Paper: https://arxiv.org/abs/2303.13516
- Code: https://github.com/nupurkmr9/concept-ablation

**Learning to Generate Semantic Layouts for Higher Text-Image Correspondence in Text-to-Image Synthesis**
- Paper:
- Code: https://github.com/pmh9960/GCDP

**HumanSD: A Native Skeleton-Guided Diffusion Model for Human Image Generation**
- Paper: https://arxiv.org/abs/2304.04269
- Code: https://github.com/IDEA-Research/HumanSD

## Image-to-Image / Image Guided

**Reinforced Disentanglement for Face Swapping without Skip Connection**
- Paper: https://arxiv.org/abs/2307.07928

**BlendFace: Re-designing Identity Encoders for Face-Swapping**
- Paper: https://arxiv.org/abs/2307.10854
- Code: https://github.com/mapooon/BlendFace

**General Image-to-Image Translation with One-Shot Image Guidance**
- Paper: https://arxiv.org/abs/2307.14352
- Code: https://github.com/CrystalNeuro/visual-concept-translator

**GaFET: Learning Geometry-aware Facial Expression Translation from In-The-Wild Images**
- Paper: https://arxiv.org/abs/2308.03413

## Others for image generation

**Conditional 360-degree Image Synthesis for Immersive Indoor Scene Decoration**
- Paper: https://arxiv.org/abs/2307.09621

**Masked Diffusion Transformer is a Strong Image Synthesizer**
- Paper: https://arxiv.org/abs/2303.14389
- Code: https://github.com/sail-sg/MDT

**Q-Diffusion: Quantizing Diffusion Models**
- Paper: https://arxiv.org/abs/2302.04304
- Code: https://github.com/Xiuyu-Li/q-diffusion

**The Euclidean Space is Evil: Hyperbolic Attribute Editing for Few-shot Image Generation**
- Paper:
- Code: https://github.com/lingxiao-li/HAE

## Video Generation

**Bidirectionally Deformable Motion Modulation For Video-based Human Pose Transfer**
- Paper: https://arxiv.org/abs/2307.07754
- Code: https://github.com/rocketappslab/bdmm

**MODA: Mapping-Once Audio-driven Portrait Animation with Dual Attentions**
- Paper: https://arxiv.org/abs/2307.10008
- Code: https://github.com/DreamtaleCore/MODA

**Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators**
- Paper: https://arxiv.org/abs/2303.13439
- Code: https://github.com/Picsart-AI-Research/Text2Video-Zero

**FateZero: Fusing Attentions for Zero-shot Text-based Video Editing**
- Paper: https://arxiv.org/abs/2303.09535
- Code: https://github.com/ChenyangQiQi/FateZero

[[Back-to-Overview](#overview)]

## Others [[back](#catalogue)]

**DDColor: Towards Photo-Realistic and Semantic-Aware Image Colorization via Dual Decoders**
- Paper: https://arxiv.org/abs/2212.11613
- Code: https://github.com/piddnad/DDColor
- Tags: Colorization

**DDFM: Denoising Diffusion Model for Multi-Modality Image Fusion**
- Paper: https://arxiv.org/abs/2303.06840
- Code: https://github.com/Zhaozixiang1228/MMIF-DDFM
- Tags: Image Fusion

**Name Your Colour For the Task: Artificially Discover Colour Naming via Colour Quantisation Transformer**
- Paper: https://arxiv.org/abs/2212.03434
- Code: https://github.com/ryeocthiv/CQFormer

**Unfolding Framework with Prior of Convolution-Transformer Mixture and Uncertainty Estimation for Video Snapshot Compressive Imaging**
- Paper: https://arxiv.org/abs/2306.11316
- Code: https://github.com/zsm1211/CTM-SCI
- Tags: Snapshot Compressive Imaging

**Deep Optics for Video Snapshot Compressive Imaging**
- Paper:
- Code: https://github.com/pwangcs/DeepOpticsSCI
- Tags: Snapshot Compressive Imaging

## Talking Head Generation

**Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation**
- Paper: https://arxiv.org/abs/2307.09906
- Code: https://github.com/harlanhong/ICCV2023-MCNET


<!--
## Virtual Try-on

## Handwriting/Font Generation
-->

